{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machines (RBMs)\n",
    "Let us assume we have some random samples of fixed-length binary sequences that we wish to express in an RBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,1,1,1,0], [0,0,1,1,0,0],[0,0,1,1,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the model\n",
    "Our RBM has 6 visible, and say 2 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_visible = 6 # = data.shape[0]\n",
    "num_hidden  = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RBM is defined by a set of weights, to which we add the biases.\n",
    "\n",
    "$E(v, h)=v^T W h + b^T h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = np.random.randn(num_visible, num_hidden)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = np.insert(weights, 0, 0, axis=0)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = np.insert(weights, 0, 0, axis=1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "learning_rate = 0.1\n",
    "training_data = np.insert(data, 0, 1, axis=1)\n",
    "num_examples = training_data.shape[0]\n",
    "training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, we need to compute the hidden activations, probabilities, and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def compute_hidden(visible):\n",
    "    num_examples = visible.shape[0]\n",
    "    pos_hidden_activations = np.dot(visible, weights)      \n",
    "    pos_hidden_probs = logistic(pos_hidden_activations)\n",
    "    pos_hidden_states = pos_hidden_probs > np.random.rand(num_examples, num_hidden + 1)\n",
    "    return pos_hidden_activations, pos_hidden_probs, pos_hidden_states\n",
    "\n",
    "test_data = training_data[:1]\n",
    "a, p, hidden_states = compute_hidden(test_data)\n",
    "print(\"input data:\", test_data)\n",
    "print(\"activation:\", a)\n",
    "print(\"probabilit:\", p)\n",
    "print(\"hidden sta:\", hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to compute the visible units to compare with the visible activations, probs., and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_visible(hidden_states):\n",
    "    num_examples = hidden_states.shape[0]\n",
    "    neg_visible_activations = np.dot(hidden_states, weights.T)\n",
    "    neg_visible_probs = logistic(neg_visible_activations)\n",
    "    neg_visible_probs[:, 0] = 1 # Fix the bias unit.\n",
    "    return neg_visible_probs\n",
    "\n",
    "neg_visible_probs = compute_visible(s)\n",
    "print(\"negative visible probabilities:\", visible_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daydream(neg_visible_probs):\n",
    "    neg_hidden_activations = np.dot(neg_visible_probs, weights)\n",
    "    neg_hidden_probs = logistic(neg_hidden_activations)\n",
    "    return neg_hidden_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(nb_epoch):\n",
    "    pos_hidden_act, pos_hidden_prob, pos_hidden_stat = compute_hidden(training_data)\n",
    "    \n",
    "    neg_visible_prob = compute_visible(pos_hidden_stat)\n",
    "    neg_hidden_prob = daydream(neg_visible_prob)\n",
    "    \n",
    "    pos_associations = np.dot(training_data.T, pos_hidden_prob)\n",
    "    neg_associations = np.dot(neg_visible_prob.T, neg_hidden_prob)\n",
    "    \n",
    "    # Update:\n",
    "    weights += learning_rate * ((pos_associations-neg_associations)/float(num_examples))\n",
    "    \n",
    "    # Error:\n",
    "    err = np.sum( (training_data - neg_visible_prob)**2 )\n",
    "    print(\"Epoch %i, error: %.3g\" % (epoch+1, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
